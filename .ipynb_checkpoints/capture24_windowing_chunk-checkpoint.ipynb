{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139561dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\"\"\"\n",
    "CAPTURE-24: janelamento 5s (tempo-based) e extração de features. Primeiro teste em notebook.\n",
    "\n",
    "Principais escolhas implementadas:\n",
    "- Janela de 5 segundos sem sobreposição (tempo-based: [t0, t0+5s))\n",
    "- Descartar linhas com NA em time,x,y,z\n",
    "- Para annotation: descartar janela se >= 50% das observações na janela tiverem annotation NA\n",
    "- Janela válida se n_samples >= min_samples (default 250)\n",
    "- Calcula estatísticas por eixo, energia, magnitude média, correlações, FFT (Welch na magnitude)\n",
    "- Gera 3 colunas de rótulos simplificados (strings) e colunas de label-encoded correspondentes\n",
    "- Inclui campos de auditoria: pid, window_start, window_end, n_samples, duration_seconds\n",
    "- Salva resultado em arquivo parquet por participante ou combinado\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fd5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_row', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 100  # Hz\n",
    "WINDOW_SECONDS = 5\n",
    "WINDOW_SIZE_SAMPLES = int(SAMPLING_RATE * WINDOW_SECONDS)  # 500\n",
    "MIN_SAMPLES = 250  # mínimo aceitável por janela\n",
    "ANNOTATION_NA_THRESHOLD = 0.5  # descartar janela se >= 50% das annotation forem NA\n",
    "FFT_NFFT = WINDOW_SIZE_SAMPLES  # usar zero-padding até 500 quando necessário\n",
    "LABEL_COLUMNS_TO_KEEP = ['label:Walmsley2020', 'label:WillettsSpecific2018', 'label:WillettsMET2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc15e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map para sexo e age\n",
    "SEX_MAP = {'F': 1, 'M': 0}\n",
    "AGE_MAP = {'18-29': 0, '30-37': 1, '38-52': 2, '53+': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretórios de entrada/saída (AJUSTAR ESSA PARTE)\n",
    "PARTICIPANT_GLOB = \"data/data_raw/capture24/capture24/P*.csv.gz\"\n",
    "METADATA_PATH = \"data/data_raw/capture24/capture24/metadata.csv\"\n",
    "ANNOT_DICT_PATH = \"data/data_raw/capture24/capture24/annotation-label-dictionary.csv\"\n",
    "OUT_DIR = \"data/data_processed/participants\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe6d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Funções utilitárias ----------\n",
    "def safe_parse_time(df, time_col='time'):\n",
    "    \"\"\"Assegura que coluna time seja datetime e ordena por time.\"\"\"\n",
    "    if not np.issubdtype(df[time_col].dtype, np.datetime64):\n",
    "        df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
    "    df = df.sort_values(time_col).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53064442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_window_features_chunked(window_df):\n",
    "    \"\"\"\n",
    "    Extrai features de aceleração + FFT completa para uma janela.\n",
    "    NÃO inclui metadata, labels ou hora cíclica.\n",
    "    \"\"\"\n",
    "\n",
    "    x = window_df['x'].to_numpy()\n",
    "    y = window_df['y'].to_numpy()\n",
    "    z = window_df['z'].to_numpy()\n",
    "\n",
    "    feats = {}\n",
    "\n",
    "    # -----------------------------\n",
    "    # Estatísticas por eixo\n",
    "    # -----------------------------\n",
    "    for axis, arr in [('x', x), ('y', y), ('z', z)]:\n",
    "        feats[f\"{axis}_mean\"] = np.mean(arr)\n",
    "        feats[f\"{axis}_std\"]  = np.std(arr)\n",
    "        feats[f\"{axis}_min\"]  = np.min(arr)\n",
    "        feats[f\"{axis}_max\"]  = np.max(arr)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Energia\n",
    "    # -----------------------------\n",
    "    feats['energy_x'] = np.mean(x**2)\n",
    "    feats['energy_y'] = np.mean(y**2)\n",
    "    feats['energy_z'] = np.mean(z**2)\n",
    "    feats['energy_total'] = np.mean(x**2 + y**2 + z**2)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Magnitude\n",
    "    # -----------------------------\n",
    "    mag = np.sqrt(x**2 + y**2 + z**2)\n",
    "    feats['magnitude_mean'] = np.mean(mag)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Correlações\n",
    "    # -----------------------------\n",
    "    def safe_corr(a, b):\n",
    "        if len(a) < 2:\n",
    "            return np.nan\n",
    "        if np.std(a) == 0 or np.std(b) == 0:\n",
    "            return np.nan\n",
    "        return float(np.corrcoef(a, b)[0, 1])\n",
    "\n",
    "    feats['corr_xy'] = safe_corr(x, y)\n",
    "    feats['corr_xz'] = safe_corr(x, z)\n",
    "    feats['corr_yz'] = safe_corr(y, z)\n",
    "\n",
    "    # -----------------------------\n",
    "    # FFT completa\n",
    "    # -----------------------------\n",
    "    mag_dt = signal.detrend(mag)\n",
    "\n",
    "    freqs, psd = signal.welch(\n",
    "        mag_dt,\n",
    "        fs=100,\n",
    "        nperseg=256,\n",
    "        nfft=500\n",
    "    )\n",
    "\n",
    "    if np.all(np.isnan(psd)):\n",
    "        feats['fft_dom_freq'] = np.nan\n",
    "        feats['fft_peak_power'] = np.nan\n",
    "    else:\n",
    "        idx = np.argmax(psd)\n",
    "        feats['fft_dom_freq'] = freqs[idx]\n",
    "        feats['fft_peak_power'] = psd[idx]\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a624c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_annotation_maps(annotation_map_df, label_columns):\n",
    "    \"\"\"\n",
    "    Cria dois dicionários globais:\n",
    "      - mapping_dicts[col]: mapa {annotation_original → label_simplificado}\n",
    "      - enc_maps[col]: mapa {label_simplificado → inteiro}\n",
    "\n",
    "    Deve ser chamado UMA ÚNICA VEZ antes do processamento de janelas.\n",
    "    \"\"\"\n",
    "\n",
    "    mapping_dicts = {}\n",
    "    enc_maps = {}\n",
    "\n",
    "    for col in label_columns:\n",
    "        # Mapeamento original → simplificado\n",
    "        mapping = dict(zip(annotation_map_df['annotation'].astype(str),\n",
    "                           annotation_map_df[col].astype(str)))\n",
    "        mapping_dicts[col] = mapping\n",
    "\n",
    "        # Encoding fixo baseado no conjunto completo de rótulos simplificados\n",
    "        unique_labels = sorted(annotation_map_df[col].dropna().unique().tolist())\n",
    "        enc_maps[col] = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "\n",
    "    return mapping_dicts, enc_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc2e2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_annotations_and_encode(window_df, mapping_dicts, enc_maps, label_columns):\n",
    "    \"\"\"\n",
    "    Faz o mapeamento da coluna 'annotation' original para os rótulos simplificados,\n",
    "    realiza majority vote e aplica encoding fixo.\n",
    "\n",
    "    - Assume que a janela já passou pelos filtros (>= 250 amostras e < 50% NA).\n",
    "    - Se houver empate → 'ambiguous' com encoding -1.\n",
    "    \"\"\"\n",
    "\n",
    "    ann = window_df['annotation'].astype(str)\n",
    "    result = {}\n",
    "\n",
    "    for col in label_columns:\n",
    "\n",
    "        mapped = ann.map(mapping_dicts[col])\n",
    "\n",
    "        # Majority vote (len(counts) nunca é 0 após filtros)\n",
    "        counts = mapped.value_counts()\n",
    "        top_count = counts.iloc[0]\n",
    "        top_labels = counts[counts == top_count].index.tolist()\n",
    "\n",
    "        if len(top_labels) > 1:\n",
    "            major = \"ambiguous\"\n",
    "        else:\n",
    "            major = top_labels[0]\n",
    "\n",
    "        result[col] = major\n",
    "\n",
    "        # Encoding fixo (consistente para todas as janelas)\n",
    "        if major == \"ambiguous\":\n",
    "            result[col + \"_enc\"] = -1\n",
    "        else:\n",
    "            result[col + \"_enc\"] = enc_maps[col][major]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc19e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_chunksize():\n",
    "    \"\"\"Escolhe chunksize automaticamente baseado na memória disponível.\"\"\"\n",
    "    free_gb = psutil.virtual_memory().available / 1e9\n",
    "\n",
    "    if free_gb >= 8:\n",
    "        return 1_200_000\n",
    "    elif free_gb >= 4:\n",
    "        return 750_000\n",
    "    else:\n",
    "        return 500_000\n",
    "\n",
    "\n",
    "def process_participant_file_chunked(\n",
    "    path,\n",
    "    metadata_df,\n",
    "    mapping_dicts,\n",
    "    enc_maps,\n",
    "    label_columns,\n",
    "    out_dir=OUT_DIR,\n",
    "):\n",
    "    \"\"\"\n",
    "    Processa UM participante usando chunks.\n",
    "    Salva incrementalmente (append) em parquet.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(path)     # \"P001.csv.gz\"\n",
    "    pid = os.path.splitext(filename)[0]   # \"P001.csv\"\n",
    "    pid = os.path.splitext(pid)[0]        # \"P001\"\n",
    "\n",
    "    print(f\"\\n=== Processando {pid} ===\")\n",
    "\n",
    "    # Obter metadata\n",
    "    meta = metadata_df.loc[metadata_df[\"pid\"] == pid].iloc[0]\n",
    "    sex_code = SEX_MAP.get(meta[\"sex\"], np.nan)\n",
    "    age_code = AGE_MAP.get(meta[\"age\"], np.nan)\n",
    "\n",
    "    # Caminho de saída\n",
    "\n",
    "    # Diretório específico do participante\n",
    "    out_dir_pid = os.path.join(out_dir, pid)\n",
    "    os.makedirs(out_dir_pid, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Escolher chunksize pelo estado atual da memória\n",
    "    chunksize = choose_chunksize()\n",
    "    print(f\"Usando chunksize: {chunksize:,}\")\n",
    "\n",
    "    reader = pd.read_csv(\n",
    "        path,\n",
    "        chunksize=chunksize,\n",
    "        usecols=['time', 'x', 'y', 'z', 'annotation'],\n",
    "        dtype={'annotation': 'string'}\n",
    "    )\n",
    "\n",
    "    total_windows = 0\n",
    "    total_valid = 0\n",
    "\n",
    "    for chunk in tqdm(reader, desc=f\"{pid} — chunks\"):\n",
    "\n",
    "        # Garantir tipos corretos\n",
    "        chunk['time'] = pd.to_datetime(chunk['time'], errors='coerce')\n",
    "        chunk = chunk.dropna(subset=['time', 'x', 'y', 'z']).reset_index(drop=True)\n",
    "        if len(chunk) == 0:\n",
    "            continue\n",
    "\n",
    "        # Tempo relativo dentro do chunk\n",
    "        t0 = chunk['time'].iloc[0]\n",
    "        chunk['t_sec'] = (chunk['time'] - t0).dt.total_seconds()\n",
    "\n",
    "        # Construir janelas\n",
    "        t_end = chunk['t_sec'].iloc[-1]\n",
    "        window_starts = np.arange(0, t_end, WINDOW_SECONDS)\n",
    "\n",
    "        rows_out = []\n",
    "\n",
    "        for ws in window_starts:\n",
    "            we = ws + WINDOW_SECONDS\n",
    "            mask = (chunk['t_sec'] >= ws) & (chunk['t_sec'] < we)\n",
    "            wdf = chunk.loc[mask]\n",
    "\n",
    "            total_windows += 1\n",
    "\n",
    "            if len(wdf) < MIN_SAMPLES:\n",
    "                continue\n",
    "            if wdf['annotation'].isna().mean() >= ANNOTATION_NA_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            total_valid += 1\n",
    "\n",
    "            # Extrair features (PARTE 1)\n",
    "            feats = compute_window_features_chunked(wdf)\n",
    "\n",
    "            # Labels: mapeamento + majority vote\n",
    "            ann = wdf[\"annotation\"].astype(str)\n",
    "\n",
    "            for col in label_columns:\n",
    "                mapped = ann.map(mapping_dicts[col])\n",
    "                counts = mapped.value_counts()\n",
    "                top = counts.max()\n",
    "                winners = counts[counts == top].index.tolist()\n",
    "\n",
    "                if len(winners) > 1:\n",
    "                    major = \"ambiguous\"\n",
    "                    enc = -1\n",
    "                else:\n",
    "                    major = winners[0]\n",
    "                    enc = enc_maps[col][major]\n",
    "\n",
    "                feats[col] = major\n",
    "                feats[col + \"_enc\"] = enc\n",
    "\n",
    "            # Hora cíclica\n",
    "            ws_datetime = t0 + timedelta(seconds=float(ws))\n",
    "            frac_hour = (\n",
    "                ws_datetime.hour\n",
    "                + ws_datetime.minute / 60\n",
    "                + ws_datetime.second / 3600\n",
    "                + ws_datetime.microsecond / (3600 * 1e6)\n",
    "            )\n",
    "            frac_day = frac_hour / 24\n",
    "\n",
    "            feats[\"hour_sin\"] = np.sin(2 * np.pi * frac_day)\n",
    "            feats[\"hour_cos\"] = np.cos(2 * np.pi * frac_day)\n",
    "\n",
    "            # Metadata\n",
    "            feats[\"pid\"] = pid\n",
    "            feats[\"sex\"] = sex_code\n",
    "            feats[\"age_group\"] = age_code\n",
    "\n",
    "            # Auditoria\n",
    "            feats[\"window_start\"] = ws_datetime\n",
    "            feats[\"window_end\"] = ws_datetime + timedelta(seconds=WINDOW_SECONDS)\n",
    "            feats[\"n_samples\"] = len(wdf)\n",
    "            feats[\"duration_seconds\"] = (\n",
    "                (wdf[\"time\"].iloc[-1] - wdf[\"time\"].iloc[0]).total_seconds()\n",
    "                if len(wdf) >= 2 else 0\n",
    "            )\n",
    "\n",
    "            rows_out.append(feats)\n",
    "\n",
    "        # Salvamento seguro por chunk (SEM append)\n",
    "        if rows_out:\n",
    "            df_out = pd.DataFrame(rows_out)\n",
    "\n",
    "            # gerar nome incremental chunk_000.parquet, chunk_001.parquet...\n",
    "            existing = [f for f in os.listdir(out_dir_pid) if f.endswith(\".parquet\")]\n",
    "            chunk_id = len(existing)\n",
    "            chunk_path = os.path.join(out_dir_pid, f\"chunk_{chunk_id:03d}.parquet\")\n",
    "\n",
    "            #reorganizando as colunas\n",
    "            audit_cols = [\"pid\", \"window_start\", \"window_end\",\"n_samples\",\n",
    "                          \"duration_seconds\", \"sex\", \"age_group\"]\n",
    "\n",
    "            label_cols = [\"label:Walmsley2020\", \"label:Walmsley2020_enc\",\n",
    "                          \"label:WillettsSpecific2018\", \"label:WillettsSpecific2018_enc\",\n",
    "                          \"label:WillettsMET2018\", \"label:WillettsMET2018_enc\",]\n",
    "\n",
    "            feature_cols = [c for c in df_out.columns\n",
    "                if c not in audit_cols + label_cols]\n",
    "\n",
    "            df_out = df_out[audit_cols + label_cols + feature_cols]\n",
    "\n",
    "            df_out.to_parquet(chunk_path, index=False)\n",
    "\n",
    "    return out_dir_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d292093",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(METADATA_PATH)\n",
    "annotation_map_df = pd.read_csv(ANNOT_DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6141c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dicts, enc_maps = build_annotation_maps(annotation_map_df, LABEL_COLUMNS_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f34802",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob(PARTICIPANT_GLOB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fdd89f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/data_raw/capture24/capture24/P*.csv.gz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTICIPANT_GLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90cbb48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/data_raw/capture24/capture24/P001.csv.gz'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df8a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P001 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P001 — chunks: 14it [02:48, 12.06s/it]\n"
     ]
    }
   ],
   "source": [
    "f= files[0]\n",
    "df_part = process_participant_file_chunked(\n",
    "    path=f,\n",
    "    metadata_df=metadata_df,\n",
    "    mapping_dicts=mapping_dicts,\n",
    "    enc_maps=enc_maps,\n",
    "    label_columns=LABEL_COLUMNS_TO_KEEP,\n",
    "    out_dir=OUT_DIR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c4e4d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 arquivos .parquet (chunks) encontrados\n",
      "['chunk_000.parquet', 'chunk_001.parquet', 'chunk_002.parquet', 'chunk_003.parquet', 'chunk_004.parquet', 'chunk_005.parquet', 'chunk_006.parquet', 'chunk_007.parquet', 'chunk_008.parquet', 'chunk_009.parquet']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "out_dir_pid = \"data/data_processed/participants/P001\"\n",
    "print(len([f for f in os.listdir(out_dir_pid) if f.endswith(\".parquet\")]), \"arquivos .parquet (chunks) encontrados\")\n",
    "print(sorted(os.listdir(out_dir_pid))[:10])  # mostra os primeiros nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01824f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>label:Walmsley2020</th>\n",
       "      <th>label:Walmsley2020_enc</th>\n",
       "      <th>label:WillettsSpecific2018</th>\n",
       "      <th>label:WillettsSpecific2018_enc</th>\n",
       "      <th>label:WillettsMET2018</th>\n",
       "      <th>label:WillettsMET2018_enc</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "      <th>z_mean</th>\n",
       "      <th>z_std</th>\n",
       "      <th>z_min</th>\n",
       "      <th>z_max</th>\n",
       "      <th>energy_x</th>\n",
       "      <th>energy_y</th>\n",
       "      <th>energy_z</th>\n",
       "      <th>energy_total</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>corr_xy</th>\n",
       "      <th>corr_xz</th>\n",
       "      <th>corr_yz</th>\n",
       "      <th>fft_dom_freq</th>\n",
       "      <th>fft_peak_power</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-13 02:18:00</td>\n",
       "      <td>2016-11-13 02:18:05</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.468161</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>-0.482334</td>\n",
       "      <td>-0.46669</td>\n",
       "      <td>-0.537512</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>-0.548902</td>\n",
       "      <td>-0.533341</td>\n",
       "      <td>0.657518</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.643077</td>\n",
       "      <td>0.673867</td>\n",
       "      <td>0.219195</td>\n",
       "      <td>0.288966</td>\n",
       "      <td>0.432345</td>\n",
       "      <td>0.940507</td>\n",
       "      <td>0.969787</td>\n",
       "      <td>-0.148480</td>\n",
       "      <td>-0.077644</td>\n",
       "      <td>0.275487</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.566406</td>\n",
       "      <td>0.824126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-13 02:18:05</td>\n",
       "      <td>2016-11-13 02:18:10</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.470069</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>-0.482334</td>\n",
       "      <td>-0.46669</td>\n",
       "      <td>-0.537045</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>-0.548902</td>\n",
       "      <td>-0.517780</td>\n",
       "      <td>0.657702</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.643077</td>\n",
       "      <td>0.673867</td>\n",
       "      <td>0.221007</td>\n",
       "      <td>0.288463</td>\n",
       "      <td>0.432585</td>\n",
       "      <td>0.942055</td>\n",
       "      <td>0.970582</td>\n",
       "      <td>-0.108382</td>\n",
       "      <td>-0.028882</td>\n",
       "      <td>0.137541</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.566706</td>\n",
       "      <td>0.823920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-13 02:18:10</td>\n",
       "      <td>2016-11-13 02:18:15</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.469694</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>-0.482334</td>\n",
       "      <td>-0.46669</td>\n",
       "      <td>-0.537947</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>-0.548902</td>\n",
       "      <td>-0.533341</td>\n",
       "      <td>0.657764</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.643077</td>\n",
       "      <td>0.673867</td>\n",
       "      <td>0.220650</td>\n",
       "      <td>0.289438</td>\n",
       "      <td>0.432665</td>\n",
       "      <td>0.942753</td>\n",
       "      <td>0.970944</td>\n",
       "      <td>-0.260468</td>\n",
       "      <td>-0.079268</td>\n",
       "      <td>0.204062</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.567005</td>\n",
       "      <td>0.823714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-13 02:18:15</td>\n",
       "      <td>2016-11-13 02:18:20</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.469287</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>-0.482334</td>\n",
       "      <td>-0.46669</td>\n",
       "      <td>-0.537512</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>-0.548902</td>\n",
       "      <td>-0.517780</td>\n",
       "      <td>0.657733</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.643077</td>\n",
       "      <td>0.673867</td>\n",
       "      <td>0.220264</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.432626</td>\n",
       "      <td>0.941857</td>\n",
       "      <td>0.970483</td>\n",
       "      <td>-0.243211</td>\n",
       "      <td>-0.092415</td>\n",
       "      <td>0.223157</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.567305</td>\n",
       "      <td>0.823508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-13 02:18:20</td>\n",
       "      <td>2016-11-13 02:18:25</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.470820</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>-0.482334</td>\n",
       "      <td>-0.46669</td>\n",
       "      <td>-0.535333</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>-0.548902</td>\n",
       "      <td>-0.517780</td>\n",
       "      <td>0.658226</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.643077</td>\n",
       "      <td>0.673867</td>\n",
       "      <td>0.221719</td>\n",
       "      <td>0.286609</td>\n",
       "      <td>0.433269</td>\n",
       "      <td>0.941597</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>-0.225457</td>\n",
       "      <td>-0.079250</td>\n",
       "      <td>0.230302</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.567604</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pid        window_start          window_end  n_samples  duration_seconds  \\\n",
       "0  P001 2016-11-13 02:18:00 2016-11-13 02:18:05        500              4.99   \n",
       "1  P001 2016-11-13 02:18:05 2016-11-13 02:18:10        500              4.99   \n",
       "2  P001 2016-11-13 02:18:10 2016-11-13 02:18:15        500              4.99   \n",
       "3  P001 2016-11-13 02:18:15 2016-11-13 02:18:20        500              4.99   \n",
       "4  P001 2016-11-13 02:18:20 2016-11-13 02:18:25        500              4.99   \n",
       "\n",
       "   sex  age_group label:Walmsley2020  label:Walmsley2020_enc  \\\n",
       "0    1          2              sleep                       3   \n",
       "1    1          2              sleep                       3   \n",
       "2    1          2              sleep                       3   \n",
       "3    1          2              sleep                       3   \n",
       "4    1          2              sleep                       3   \n",
       "\n",
       "  label:WillettsSpecific2018  label:WillettsSpecific2018_enc  \\\n",
       "0                      sleep                               5   \n",
       "1                      sleep                               5   \n",
       "2                      sleep                               5   \n",
       "3                      sleep                               5   \n",
       "4                      sleep                               5   \n",
       "\n",
       "  label:WillettsMET2018  label:WillettsMET2018_enc    x_mean     x_std  \\\n",
       "0                 sleep                          5 -0.468161  0.004565   \n",
       "1                 sleep                          5 -0.470069  0.006437   \n",
       "2                 sleep                          5 -0.469694  0.006162   \n",
       "3                 sleep                          5 -0.469287  0.005821   \n",
       "4                 sleep                          5 -0.470820  0.006896   \n",
       "\n",
       "      x_min    x_max    y_mean     y_std     y_min     y_max    z_mean  \\\n",
       "0 -0.482334 -0.46669 -0.537512  0.006892 -0.548902 -0.533341  0.657518   \n",
       "1 -0.482334 -0.46669 -0.537045  0.006771 -0.548902 -0.517780  0.657702   \n",
       "2 -0.482334 -0.46669 -0.537947  0.007104 -0.548902 -0.533341  0.657764   \n",
       "3 -0.482334 -0.46669 -0.537512  0.006962 -0.548902 -0.517780  0.657733   \n",
       "4 -0.482334 -0.46669 -0.535333  0.005291 -0.548902 -0.517780  0.658226   \n",
       "\n",
       "      z_std     z_min     z_max  energy_x  energy_y  energy_z  energy_total  \\\n",
       "0  0.003960  0.643077  0.673867  0.219195  0.288966  0.432345      0.940507   \n",
       "1  0.003627  0.643077  0.673867  0.221007  0.288463  0.432585      0.942055   \n",
       "2  0.003369  0.643077  0.673867  0.220650  0.289438  0.432665      0.942753   \n",
       "3  0.003567  0.643077  0.673867  0.220264  0.288967  0.432626      0.941857   \n",
       "4  0.002743  0.643077  0.673867  0.221719  0.286609  0.433269      0.941597   \n",
       "\n",
       "   magnitude_mean   corr_xy   corr_xz   corr_yz  fft_dom_freq  fft_peak_power  \\\n",
       "0        0.969787 -0.148480 -0.077644  0.275487           0.4        0.000005   \n",
       "1        0.970582 -0.108382 -0.028882  0.137541           3.6        0.000008   \n",
       "2        0.970944 -0.260468 -0.079268  0.204062           0.4        0.000002   \n",
       "3        0.970483 -0.243211 -0.092415  0.223157           0.4        0.000001   \n",
       "4        0.970350 -0.225457 -0.079250  0.230302           8.8        0.000002   \n",
       "\n",
       "   hour_sin  hour_cos  \n",
       "0  0.566406  0.824126  \n",
       "1  0.566706  0.823920  \n",
       "2  0.567005  0.823714  \n",
       "3  0.567305  0.823508  \n",
       "4  0.567604  0.823302  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/data_processed/participants/P001/chunk_000.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fcd914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dacb2f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pid', 'window_start', 'window_end', 'n_samples', 'duration_seconds',\n",
       "       'sex', 'age_group', 'label:Walmsley2020', 'label:Walmsley2020_enc',\n",
       "       'label:WillettsSpecific2018', 'label:WillettsSpecific2018_enc',\n",
       "       'label:WillettsMET2018', 'label:WillettsMET2018_enc', 'x_mean', 'x_std',\n",
       "       'x_min', 'x_max', 'y_mean', 'y_std', 'y_min', 'y_max', 'z_mean',\n",
       "       'z_std', 'z_min', 'z_max', 'energy_x', 'energy_y', 'energy_z',\n",
       "       'energy_total', 'magnitude_mean', 'corr_xy', 'corr_xz', 'corr_yz',\n",
       "       'fft_dom_freq', 'fft_peak_power', 'hour_sin', 'hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13c20bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>label:Walmsley2020</th>\n",
       "      <th>label:Walmsley2020_enc</th>\n",
       "      <th>label:WillettsSpecific2018</th>\n",
       "      <th>label:WillettsSpecific2018_enc</th>\n",
       "      <th>label:WillettsMET2018</th>\n",
       "      <th>label:WillettsMET2018_enc</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "      <th>z_mean</th>\n",
       "      <th>z_std</th>\n",
       "      <th>z_min</th>\n",
       "      <th>z_max</th>\n",
       "      <th>energy_x</th>\n",
       "      <th>energy_y</th>\n",
       "      <th>energy_z</th>\n",
       "      <th>energy_total</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>corr_xy</th>\n",
       "      <th>corr_xz</th>\n",
       "      <th>corr_yz</th>\n",
       "      <th>fft_dom_freq</th>\n",
       "      <th>fft_peak_power</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 02:38:00</td>\n",
       "      <td>2016-11-14 02:38:05</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.977192</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>-0.967408</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.180042</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.165224</td>\n",
       "      <td>0.180820</td>\n",
       "      <td>0.954962</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.988011</td>\n",
       "      <td>0.993959</td>\n",
       "      <td>-0.103857</td>\n",
       "      <td>-0.045651</td>\n",
       "      <td>0.030106</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.636078</td>\n",
       "      <td>0.771625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 02:38:05</td>\n",
       "      <td>2016-11-14 02:38:10</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.977202</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>-0.967408</td>\n",
       "      <td>0.024420</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.180105</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.165224</td>\n",
       "      <td>0.180820</td>\n",
       "      <td>0.954980</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.032447</td>\n",
       "      <td>0.988056</td>\n",
       "      <td>0.993982</td>\n",
       "      <td>-0.190548</td>\n",
       "      <td>-0.054464</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.636359</td>\n",
       "      <td>0.771393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 02:38:10</td>\n",
       "      <td>2016-11-14 02:38:15</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.976248</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>-0.967408</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.180054</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.165224</td>\n",
       "      <td>0.180820</td>\n",
       "      <td>0.953120</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>0.986188</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>-0.114458</td>\n",
       "      <td>-0.044656</td>\n",
       "      <td>-0.025016</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.636639</td>\n",
       "      <td>0.771162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 02:38:15</td>\n",
       "      <td>2016-11-14 02:38:20</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.977869</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>-0.967408</td>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.180009</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.165224</td>\n",
       "      <td>0.196215</td>\n",
       "      <td>0.956283</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.032414</td>\n",
       "      <td>0.989331</td>\n",
       "      <td>0.994625</td>\n",
       "      <td>-0.184093</td>\n",
       "      <td>0.065115</td>\n",
       "      <td>-0.032377</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.636920</td>\n",
       "      <td>0.770930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 02:38:20</td>\n",
       "      <td>2016-11-14 02:38:25</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.977222</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>-0.967408</td>\n",
       "      <td>0.024417</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.179984</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.165224</td>\n",
       "      <td>0.196215</td>\n",
       "      <td>0.955021</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.032407</td>\n",
       "      <td>0.988056</td>\n",
       "      <td>0.993982</td>\n",
       "      <td>-0.237423</td>\n",
       "      <td>-0.028480</td>\n",
       "      <td>-0.070048</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.637200</td>\n",
       "      <td>0.770699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pid        window_start          window_end  n_samples  duration_seconds  \\\n",
       "0  P001 2016-11-14 02:38:00 2016-11-14 02:38:05        500              4.99   \n",
       "1  P001 2016-11-14 02:38:05 2016-11-14 02:38:10        500              4.99   \n",
       "2  P001 2016-11-14 02:38:10 2016-11-14 02:38:15        500              4.99   \n",
       "3  P001 2016-11-14 02:38:15 2016-11-14 02:38:20        500              4.99   \n",
       "4  P001 2016-11-14 02:38:20 2016-11-14 02:38:25        500              4.99   \n",
       "\n",
       "   sex  age_group label:Walmsley2020  label:Walmsley2020_enc  \\\n",
       "0    1          2              sleep                       3   \n",
       "1    1          2              sleep                       3   \n",
       "2    1          2              sleep                       3   \n",
       "3    1          2              sleep                       3   \n",
       "4    1          2              sleep                       3   \n",
       "\n",
       "  label:WillettsSpecific2018  label:WillettsSpecific2018_enc  \\\n",
       "0                      sleep                               5   \n",
       "1                      sleep                               5   \n",
       "2                      sleep                               5   \n",
       "3                      sleep                               5   \n",
       "4                      sleep                               5   \n",
       "\n",
       "  label:WillettsMET2018  label:WillettsMET2018_enc    x_mean     x_std  \\\n",
       "0                 sleep                          5 -0.977192  0.007578   \n",
       "1                 sleep                          5 -0.977202  0.007575   \n",
       "2                 sleep                          5 -0.976248  0.007763   \n",
       "3                 sleep                          5 -0.977869  0.007377   \n",
       "4                 sleep                          5 -0.977222  0.007571   \n",
       "\n",
       "      x_min     x_max    y_mean     y_std     y_min     y_max    z_mean  \\\n",
       "0 -0.983116 -0.967408  0.024293  0.005817  0.011339  0.026919  0.180042   \n",
       "1 -0.983116 -0.967408  0.024420  0.005705  0.011339  0.026919  0.180105   \n",
       "2 -0.983116 -0.967408  0.024704  0.005432  0.011339  0.026919  0.180054   \n",
       "3 -0.983116 -0.967408  0.024547  0.005586  0.011339  0.026919  0.180009   \n",
       "4 -0.983116 -0.967408  0.024417  0.005704  0.011339  0.026919  0.179984   \n",
       "\n",
       "      z_std     z_min     z_max  energy_x  energy_y  energy_z  energy_total  \\\n",
       "0  0.003228  0.165224  0.180820  0.954962  0.000624  0.032425      0.988011   \n",
       "1  0.003015  0.165224  0.180820  0.954980  0.000629  0.032447      0.988056   \n",
       "2  0.003018  0.165224  0.180820  0.953120  0.000640  0.032429      0.986188   \n",
       "3  0.003299  0.165224  0.196215  0.956283  0.000634  0.032414      0.989331   \n",
       "4  0.003502  0.165224  0.196215  0.955021  0.000629  0.032407      0.988056   \n",
       "\n",
       "   magnitude_mean   corr_xy   corr_xz   corr_yz  fft_dom_freq  fft_peak_power  \\\n",
       "0        0.993959 -0.103857 -0.045651  0.030106           5.4        0.000008   \n",
       "1        0.993982 -0.190548 -0.054464  0.049911           6.2        0.000007   \n",
       "2        0.993040 -0.114458 -0.044656 -0.025016           5.2        0.000008   \n",
       "3        0.994625 -0.184093  0.065115 -0.032377           5.2        0.000010   \n",
       "4        0.993982 -0.237423 -0.028480 -0.070048           5.4        0.000009   \n",
       "\n",
       "   hour_sin  hour_cos  \n",
       "0  0.636078  0.771625  \n",
       "1  0.636359  0.771393  \n",
       "2  0.636639  0.771162  \n",
       "3  0.636920  0.770930  \n",
       "4  0.637200  0.770699  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/data_processed/participants/P001/chunk_011.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e831e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 37)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "204f93bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>label:Walmsley2020</th>\n",
       "      <th>label:Walmsley2020_enc</th>\n",
       "      <th>label:WillettsSpecific2018</th>\n",
       "      <th>label:WillettsSpecific2018_enc</th>\n",
       "      <th>label:WillettsMET2018</th>\n",
       "      <th>label:WillettsMET2018_enc</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "      <th>z_mean</th>\n",
       "      <th>z_std</th>\n",
       "      <th>z_min</th>\n",
       "      <th>z_max</th>\n",
       "      <th>energy_x</th>\n",
       "      <th>energy_y</th>\n",
       "      <th>energy_z</th>\n",
       "      <th>energy_total</th>\n",
       "      <th>magnitude_mean</th>\n",
       "      <th>corr_xy</th>\n",
       "      <th>corr_xz</th>\n",
       "      <th>corr_yz</th>\n",
       "      <th>fft_dom_freq</th>\n",
       "      <th>fft_peak_power</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 05:23:00</td>\n",
       "      <td>2016-11-14 05:23:05</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.298680</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>-0.310256</td>\n",
       "      <td>-0.294612</td>\n",
       "      <td>0.180640</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.166915</td>\n",
       "      <td>0.182476</td>\n",
       "      <td>-0.941242</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>-0.942627</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.089257</td>\n",
       "      <td>0.032656</td>\n",
       "      <td>0.885955</td>\n",
       "      <td>1.007868</td>\n",
       "      <td>1.003915</td>\n",
       "      <td>-0.146141</td>\n",
       "      <td>-0.036645</td>\n",
       "      <td>-0.014947</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.986996</td>\n",
       "      <td>0.160743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 05:23:05</td>\n",
       "      <td>2016-11-14 05:23:10</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.299837</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>-0.310256</td>\n",
       "      <td>-0.294612</td>\n",
       "      <td>0.180329</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.166915</td>\n",
       "      <td>0.182476</td>\n",
       "      <td>-0.941704</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>-0.942627</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.089957</td>\n",
       "      <td>0.032547</td>\n",
       "      <td>0.886819</td>\n",
       "      <td>1.009323</td>\n",
       "      <td>1.004642</td>\n",
       "      <td>-0.172695</td>\n",
       "      <td>-0.017499</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.987055</td>\n",
       "      <td>0.160384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 05:23:10</td>\n",
       "      <td>2016-11-14 05:23:15</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>-0.310256</td>\n",
       "      <td>-0.294612</td>\n",
       "      <td>0.180204</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.166915</td>\n",
       "      <td>0.182476</td>\n",
       "      <td>-0.941334</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>-0.942627</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.089522</td>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.886128</td>\n",
       "      <td>1.008153</td>\n",
       "      <td>1.004058</td>\n",
       "      <td>-0.137888</td>\n",
       "      <td>-0.046238</td>\n",
       "      <td>0.043534</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>0.160025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 05:23:15</td>\n",
       "      <td>2016-11-14 05:23:20</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.298398</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>-0.310256</td>\n",
       "      <td>-0.294612</td>\n",
       "      <td>0.179986</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.166915</td>\n",
       "      <td>0.182476</td>\n",
       "      <td>-0.941642</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>-0.942627</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.089086</td>\n",
       "      <td>0.032428</td>\n",
       "      <td>0.886704</td>\n",
       "      <td>1.008218</td>\n",
       "      <td>1.004091</td>\n",
       "      <td>-0.182912</td>\n",
       "      <td>-0.004884</td>\n",
       "      <td>-0.064194</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.987171</td>\n",
       "      <td>0.159666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P001</td>\n",
       "      <td>2016-11-14 05:23:20</td>\n",
       "      <td>2016-11-14 05:23:25</td>\n",
       "      <td>500</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>sleep</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.297115</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>-0.310256</td>\n",
       "      <td>-0.294612</td>\n",
       "      <td>0.178150</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.166915</td>\n",
       "      <td>0.182476</td>\n",
       "      <td>-0.941396</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>-0.942627</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.088310</td>\n",
       "      <td>0.031786</td>\n",
       "      <td>0.886243</td>\n",
       "      <td>1.006340</td>\n",
       "      <td>1.003155</td>\n",
       "      <td>-0.161223</td>\n",
       "      <td>-0.092502</td>\n",
       "      <td>-0.014480</td>\n",
       "      <td>48.8</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.987229</td>\n",
       "      <td>0.159307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pid        window_start          window_end  n_samples  duration_seconds  \\\n",
       "0  P001 2016-11-14 05:23:00 2016-11-14 05:23:05        500              4.99   \n",
       "1  P001 2016-11-14 05:23:05 2016-11-14 05:23:10        500              4.99   \n",
       "2  P001 2016-11-14 05:23:10 2016-11-14 05:23:15        500              4.99   \n",
       "3  P001 2016-11-14 05:23:15 2016-11-14 05:23:20        500              4.99   \n",
       "4  P001 2016-11-14 05:23:20 2016-11-14 05:23:25        500              4.99   \n",
       "\n",
       "   sex  age_group label:Walmsley2020  label:Walmsley2020_enc  \\\n",
       "0    1          2              sleep                       3   \n",
       "1    1          2              sleep                       3   \n",
       "2    1          2              sleep                       3   \n",
       "3    1          2              sleep                       3   \n",
       "4    1          2              sleep                       3   \n",
       "\n",
       "  label:WillettsSpecific2018  label:WillettsSpecific2018_enc  \\\n",
       "0                      sleep                               5   \n",
       "1                      sleep                               5   \n",
       "2                      sleep                               5   \n",
       "3                      sleep                               5   \n",
       "4                      sleep                               5   \n",
       "\n",
       "  label:WillettsMET2018  label:WillettsMET2018_enc    x_mean     x_std  \\\n",
       "0                 sleep                          5 -0.298680  0.006862   \n",
       "1                 sleep                          5 -0.299837  0.007378   \n",
       "2                 sleep                          5 -0.299118  0.007084   \n",
       "3                 sleep                          5 -0.298398  0.006700   \n",
       "4                 sleep                          5 -0.297115  0.005735   \n",
       "\n",
       "      x_min     x_max    y_mean     y_std     y_min     y_max    z_mean  \\\n",
       "0 -0.310256 -0.294612  0.180640  0.005020  0.166915  0.182476 -0.941242   \n",
       "1 -0.310256 -0.294612  0.180329  0.005367  0.166915  0.182476 -0.941704   \n",
       "2 -0.310256 -0.294612  0.180204  0.005495  0.166915  0.182476 -0.941334   \n",
       "3 -0.310256 -0.294612  0.179986  0.005705  0.166915  0.182476 -0.941642   \n",
       "4 -0.310256 -0.294612  0.178150  0.006972  0.166915  0.182476 -0.941396   \n",
       "\n",
       "      z_std     z_min     z_max  energy_x  energy_y  energy_z  energy_total  \\\n",
       "0  0.004406 -0.942627 -0.927232  0.089257  0.032656  0.885955      1.007868   \n",
       "1  0.003656 -0.942627 -0.927232  0.089957  0.032547  0.886819      1.009323   \n",
       "2  0.004270 -0.942627 -0.927232  0.089522  0.032504  0.886128      1.008153   \n",
       "3  0.003768 -0.942627 -0.927232  0.089086  0.032428  0.886704      1.008218   \n",
       "4  0.004177 -0.942627 -0.927232  0.088310  0.031786  0.886243      1.006340   \n",
       "\n",
       "   magnitude_mean   corr_xy   corr_xz   corr_yz  fft_dom_freq  fft_peak_power  \\\n",
       "0        1.003915 -0.146141 -0.036645 -0.014947          45.6        0.000002   \n",
       "1        1.004642 -0.172695 -0.017499  0.027836          15.8        0.000001   \n",
       "2        1.004058 -0.137888 -0.046238  0.043534           5.8        0.000002   \n",
       "3        1.004091 -0.182912 -0.004884 -0.064194           4.4        0.000002   \n",
       "4        1.003155 -0.161223 -0.092502 -0.014480          48.8        0.000001   \n",
       "\n",
       "   hour_sin  hour_cos  \n",
       "0  0.986996  0.160743  \n",
       "1  0.987055  0.160384  \n",
       "2  0.987113  0.160025  \n",
       "3  0.987171  0.159666  \n",
       "4  0.987229  0.159307  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/data_processed/participants/P001/chunk_013.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de8c1efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689e3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_participants(\n",
    "    pattern=PARTICIPANT_GLOB,\n",
    "    metadata_df=None,\n",
    "    mapping_dicts=None,\n",
    "    enc_maps=None,\n",
    "    label_columns=LABEL_COLUMNS_TO_KEEP,\n",
    "    out_dir=OUT_DIR\n",
    "):\n",
    "    \"\"\"\n",
    "    Processa TODOS os participantes usando o pipeline chunked.\n",
    "\n",
    "    - pattern: glob com caminho dos arquivos PXXX.csv.gz\n",
    "    - metadata_df: dataframe carregado previamente\n",
    "    - mapping_dicts, enc_maps: gerados por build_annotation_maps\n",
    "    - label_columns: lista das colunas simplificadas que serão usadas\n",
    "    - out_dir: diretório base para saída\n",
    "\n",
    "    Retorna lista dos diretórios gerados (1 por participante).\n",
    "    \"\"\"\n",
    "\n",
    "    files = sorted(glob(pattern))\n",
    "    if len(files) == 0:\n",
    "        print(\"Nenhum arquivo encontrado com o padrão:\", pattern)\n",
    "        return []\n",
    "\n",
    "    print(f\"=== Iniciando processamento de {len(files)} participantes ===\\n\")\n",
    "\n",
    "    dirs_out = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            out_pid = process_participant_file_chunked(\n",
    "                path=f,\n",
    "                metadata_df=metadata_df,\n",
    "                mapping_dicts=mapping_dicts,\n",
    "                enc_maps=enc_maps,\n",
    "                label_columns=label_columns,\n",
    "                out_dir=out_dir\n",
    "            )\n",
    "            dirs_out.append(out_pid)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERRO ao processar {f}:\\n{e}\\n\")\n",
    "            continue\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"\\n=== Finalizado processamento de todos os participantes ===\")\n",
    "    print(f\"Tempo total: {(t1 - t0)/60:.2f} minutos\\n\")\n",
    "\n",
    "    return dirs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfa57339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iniciando processamento de 151 participantes ===\n",
      "\n",
      "\n",
      "=== Processando P001 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P001 — chunks: 14it [02:57, 12.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P002 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P002 — chunks: 12it [02:15, 11.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P003 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P003 — chunks: 13it [02:32, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P004 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P004 — chunks: 11it [02:12, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P005 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P005 — chunks: 14it [02:47, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P006 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P006 — chunks: 16it [03:09, 11.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P007 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P007 — chunks: 14it [02:36, 11.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P008 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P008 — chunks: 13it [02:20, 10.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P009 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P009 — chunks: 10it [00:54,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P010 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P010 — chunks: 13it [01:29,  6.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P011 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P011 — chunks: 13it [01:31,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P012 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P012 — chunks: 13it [01:34,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P013 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P013 — chunks: 12it [01:26,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P014 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P014 — chunks: 14it [01:40,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P015 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P015 — chunks: 13it [01:25,  6.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P016 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P016 — chunks: 12it [01:23,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P017 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P017 — chunks: 13it [01:31,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P018 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P018 — chunks: 12it [01:06,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P019 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P019 — chunks: 13it [01:34,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P020 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P020 — chunks: 11it [01:06,  6.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P021 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P021 — chunks: 13it [01:37,  7.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P022 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P022 — chunks: 15it [01:46,  7.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P023 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P023 — chunks: 14it [01:20,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P024 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P024 — chunks: 14it [01:43,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P025 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P025 — chunks: 13it [01:37,  7.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P026 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P026 — chunks: 12it [01:16,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P027 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P027 — chunks: 13it [01:21,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P028 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P028 — chunks: 13it [01:14,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P029 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P029 — chunks: 14it [01:21,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P030 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P030 — chunks: 13it [02:24, 11.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P031 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P031 — chunks: 13it [01:32,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P032 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P032 — chunks: 13it [02:58, 13.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P033 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P033 — chunks: 13it [03:20, 15.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P034 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P034 — chunks: 14it [02:02,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P035 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P035 — chunks: 13it [14:53, 68.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P036 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P036 — chunks: 12it [01:17,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P037 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P037 — chunks: 14it [01:26,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P038 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P038 — chunks: 13it [01:35,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P039 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P039 — chunks: 13it [01:22,  6.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P040 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P040 — chunks: 12it [01:25,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P041 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P041 — chunks: 13it [01:31,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P042 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P042 — chunks: 13it [01:33,  7.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P043 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P043 — chunks: 13it [02:06,  9.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P044 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P044 — chunks: 13it [01:48,  8.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P045 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P045 — chunks: 12it [01:28,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P046 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P046 — chunks: 13it [01:40,  7.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P047 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P047 — chunks: 11it [01:34,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P048 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P048 — chunks: 13it [01:36,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P049 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P049 — chunks: 13it [01:53,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P050 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P050 — chunks: 12it [01:42,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P051 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P051 — chunks: 12it [01:46,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P052 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P052 — chunks: 12it [01:34,  7.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P053 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P053 — chunks: 13it [02:01,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P054 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P054 — chunks: 15it [02:25,  9.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P055 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P055 — chunks: 13it [01:40,  7.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P056 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P056 — chunks: 13it [01:50,  8.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P057 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P057 — chunks: 13it [01:43,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P058 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P058 — chunks: 13it [01:46,  8.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P059 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P059 — chunks: 13it [01:40,  7.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P060 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P060 — chunks: 13it [01:39,  7.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P061 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P061 — chunks: 13it [01:41,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P062 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P062 — chunks: 12it [01:46,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P063 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P063 — chunks: 13it [01:30,  6.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P064 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P064 — chunks: 13it [01:48,  8.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P065 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P065 — chunks: 12it [01:41,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P066 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P066 — chunks: 14it [02:01,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P067 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P067 — chunks: 13it [01:43,  7.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P068 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P068 — chunks: 12it [01:48,  9.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P069 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P069 — chunks: 13it [01:40,  7.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P070 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P070 — chunks: 13it [01:53,  8.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P071 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P071 — chunks: 14it [01:36,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P072 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P072 — chunks: 10it [01:32,  8.97s/it]/tmp/ipykernel_50078/912912241.py:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk['time'] = pd.to_datetime(chunk['time'], errors='coerce')\n",
      "P072 — chunks: 13it [01:50,  8.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P073 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P073 — chunks: 14it [01:58,  8.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P074 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P074 — chunks: 15it [01:49,  7.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P075 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P075 — chunks: 13it [01:32,  7.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P076 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P076 — chunks: 14it [01:57,  8.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P077 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P077 — chunks: 11it [01:26,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P078 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P078 — chunks: 13it [01:59,  9.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P079 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P079 — chunks: 12it [01:36,  8.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P080 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P080 — chunks: 15it [02:06,  8.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P081 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P081 — chunks: 7it [01:00,  8.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P082 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P082 — chunks: 12it [01:35,  7.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P083 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P083 — chunks: 13it [01:37,  7.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P084 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P084 — chunks: 14it [01:53,  8.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P085 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P085 — chunks: 13it [01:45,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P086 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P086 — chunks: 13it [01:51,  8.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P087 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P087 — chunks: 11it [01:35,  8.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P088 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P088 — chunks: 14it [01:30,  6.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P089 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P089 — chunks: 12it [01:43,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P090 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P090 — chunks: 13it [01:49,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P091 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P091 — chunks: 13it [01:51,  8.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P092 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P092 — chunks: 13it [01:42,  7.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P093 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P093 — chunks: 13it [01:56,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P094 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P094 — chunks: 8it [00:54,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P095 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P095 — chunks: 13it [01:27,  6.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P096 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P096 — chunks: 12it [01:45,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P097 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P097 — chunks: 14it [02:01,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P098 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P098 — chunks: 15it [02:06,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P099 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P099 — chunks: 13it [01:42,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P100 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P100 — chunks: 14it [02:03,  8.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P101 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P101 — chunks: 13it [01:53,  8.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P102 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P102 — chunks: 13it [01:31,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P103 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P103 — chunks: 12it [01:48,  9.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P104 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P104 — chunks: 13it [01:46,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P105 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P105 — chunks: 13it [01:38,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P106 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P106 — chunks: 13it [01:30,  6.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P107 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P107 — chunks: 12it [01:43,  8.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P108 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P108 — chunks: 14it [01:48,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P109 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P109 — chunks: 12it [01:38,  8.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P110 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P110 — chunks: 13it [01:51,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P111 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P111 — chunks: 14it [02:05,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P112 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P112 — chunks: 13it [01:13,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P113 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P113 — chunks: 14it [01:54,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P114 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P114 — chunks: 13it [01:51,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P115 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P115 — chunks: 13it [01:42,  7.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P116 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P116 — chunks: 13it [01:41,  7.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P117 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P117 — chunks: 13it [01:39,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P118 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P118 — chunks: 13it [01:17,  5.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P119 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P119 — chunks: 13it [01:43,  7.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P120 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P120 — chunks: 13it [01:33,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P121 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P121 — chunks: 14it [02:02,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P122 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P122 — chunks: 11it [01:21,  7.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P123 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P123 — chunks: 11it [01:27,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P124 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P124 — chunks: 11it [01:37,  8.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P125 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P125 — chunks: 14it [02:03,  8.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P126 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P126 — chunks: 12it [01:43,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P127 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P127 — chunks: 10it [01:25,  8.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P128 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P128 — chunks: 13it [02:01,  9.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P129 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P129 — chunks: 13it [01:41,  7.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P130 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P130 — chunks: 13it [01:52,  8.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P131 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P131 — chunks: 14it [01:51,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P132 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P132 — chunks: 13it [01:41,  7.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P133 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P133 — chunks: 15it [02:12,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P134 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P134 — chunks: 13it [01:33,  7.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P135 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P135 — chunks: 13it [01:38,  7.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P136 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P136 — chunks: 9it [01:15,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P137 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P137 — chunks: 13it [01:32,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P138 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P138 — chunks: 13it [01:33,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P139 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P139 — chunks: 11it [01:27,  7.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P140 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P140 — chunks: 11it [01:31,  8.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P141 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P141 — chunks: 14it [01:36,  6.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P142 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P142 — chunks: 8it [01:02,  7.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P143 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P143 — chunks: 13it [01:27,  6.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P144 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P144 — chunks: 12it [01:37,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P145 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P145 — chunks: 14it [01:49,  7.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P146 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P146 — chunks: 13it [01:59,  9.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P147 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P147 — chunks: 13it [01:50,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P148 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P148 — chunks: 13it [01:40,  7.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P149 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P149 — chunks: 13it [01:32,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P150 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P150 — chunks: 13it [01:55,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando P151 ===\n",
      "Usando chunksize: 750,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P151 — chunks: 15it [01:51,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Finalizado processamento de todos os participantes ===\n",
      "Tempo total: 275.70 minutos\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dirs = process_all_participants(\n",
    "    pattern=PARTICIPANT_GLOB,\n",
    "    metadata_df=metadata_df,\n",
    "    mapping_dicts=mapping_dicts,\n",
    "    enc_maps=enc_maps,\n",
    "    label_columns=LABEL_COLUMNS_TO_KEEP,\n",
    "    out_dir=OUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0d6e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/data_processed/participants/P075/chunk_005.parquet\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2881f26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/data_processed/participants'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "878c29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sanity_check = 'data/data_processed/participants/amostra_P075_chunk_005.csv'\n",
    "df.to_csv(file_sanity_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74c7e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/data_processed/participants/P148/chunk_011.parquet\").head()\n",
    "file_sanity_check = 'data/data_processed/participants/amostra_P148_chunk_011.csv'\n",
    "df.to_csv(file_sanity_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837ddcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
